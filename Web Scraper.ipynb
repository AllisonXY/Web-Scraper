{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6e4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pandas import DataFrame\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "\n",
    "domain_url = \"https://domainurl.com\"  # replace with domain url\n",
    "json_link = \"/latest.json?ascending=false&no_definitions=true&page={}\"\n",
    "\n",
    "starting_url=\"https://domainurl.com/t/\" # replace with domain url\n",
    "\n",
    "# Crawl post URLs from the forum Json pages\n",
    "def url_crawler(num):  \n",
    "    ending_urls={}  # {post titile: ending url}\n",
    "    is_last_page=False\n",
    "    api_url = (domain_url + json_link).format(num)\n",
    "    \n",
    "    page = requests.get(api_url)\n",
    "    page_json= page.json()  \n",
    "    topic_list= page_json[\"topic_list\"]\n",
    "    topics=topic_list[\"topics\"]\n",
    "\n",
    "    if len(topics)>0:\n",
    "        for topic in topics:     #get all post urls in this json page\n",
    "            post_id= topic[\"id\"]\n",
    "            post_slug= topic[\"slug\"] \n",
    "            post_title= topic[\"title\"] \n",
    "            ending_urls[post_title]= post_slug+\"/\"+ str(post_id) \n",
    "            time.sleep(3) \n",
    "            \n",
    "        if \"more_topics_url\" not in topic_list.keys():  #on last page\n",
    "            is_last_page= True\n",
    "    else:  # pages after the last page\n",
    "        is_last_page= True  \n",
    "    return is_last_page,ending_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "985f554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "forum_categories={\"About the forum\":[\"Our forum is changing\",\n",
    "                                     \"Get help using the forum\"],\n",
    "                 \"About me\":[\"Introductions and personal stories\"],\n",
    "                 \"About Parkinson's and health\":[\"Wellbeing\",\n",
    "                                                 \"Treatments and therapies\",\n",
    "                                                 \"Impulsive and compulsive behaviour\",\n",
    "                                                 \"Newly diagnosed\",\n",
    "                                                 \"Symptoms\"],\n",
    "                  \"Living with Parkinson's\":[\"Carers, friends and family\",\n",
    "                                             \"Daily life\",\n",
    "                                             \"Work, benefits and money\",\n",
    "                                             \"Young Onset Parkinson's\"],\n",
    "                  \"Taking Control\":[\"Ways to take control\"],\n",
    "                  \"Research\":[\"Research discussion\",\n",
    "                              \"Research opportunities\",\n",
    "                              \"Research Support Network\"],\n",
    "                  \"Social and creative\":[],\n",
    "                  \"Get involved\":[\"News, events and taking part\",\n",
    "                                  \"About the community\"]                 \n",
    "                 }\n",
    "\n",
    "forum_subcategories=[]\n",
    "for line in list(forum_categories.values()):\n",
    "    for sub in line:\n",
    "        forum_subcategories.append(sub)\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21fca3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(tail):\n",
    "    return starting_url + tail\n",
    "    \n",
    "def strip_span_tags(str,is_username):\n",
    "    try:\n",
    "        if (is_username):\n",
    "            str=str.replace('<span itemprop=\"name\">',\"\")  #<span itemprop=\"name\">\n",
    "        else: #category and subcategory\n",
    "            str=str.replace('<span class=\"category-name\" itemprop=\"name\">',\"\")\n",
    "        str=str.replace('</span>',\"\")  \n",
    "    except AttributeError:\n",
    "        str=str\n",
    "    return str\n",
    "\n",
    "# iteratively visit all post links and perform scraping via BeautifulSoap & store\n",
    "def post_crawler(title,url):\n",
    "    page = requests.get(url)  # get request from url\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")# convert the text\n",
    "    # print(soup)\n",
    "\n",
    "    post_title= title  #1.title\n",
    "\n",
    "    metadata= soup.findAll(\"span\", itemprop=\"name\")\n",
    "    datum1= strip_span_tags(str(metadata[0]),False)  #2. category(or username1 in old posts)\n",
    "    datum2= strip_span_tags(str(metadata[1]),False)   #3. subcategory (or username2)\n",
    "    datum3= strip_span_tags(str(metadata[2]),True)  #4. username (or username3)\n",
    "    \n",
    "    # old posts do not have category and subcate\n",
    "    post_category,post_subcate= None,None\n",
    "    if datum1 in forum_categories.keys():  #strip them as categories first\n",
    "        post_category = datum1\n",
    "    if datum2 in forum_subcategories:\n",
    "        post_subcate = datum2\n",
    "        \n",
    "    if not post_category is None and not post_subcate is None: #new posts\n",
    "        post_username= datum3\n",
    "    else: #old posts\n",
    "        post_username=strip_span_tags(str(metadata[0]),True) #is_username\n",
    "    \n",
    "\n",
    "    post_time=soup.find(\"time\")\n",
    "    if post_time.has_attr('datetime'): \n",
    "        post_time= post_time['datetime']   #5. time\n",
    "    \n",
    "    post_content=soup.find(\"div\",itemprop=\"articleBody\")\n",
    "    post_content=str(post_content)\n",
    "    post_content= post_content.strip('<div class=\"post\" itemprop=\"articleBody\">')\n",
    "    post_content= post_content.strip('<p>')\n",
    "    post_content= post_content.strip('</p>')  \n",
    "    post_content= post_content.strip('\\n        ')\n",
    "    post_content= post_content.strip('\\n          ') #6. initiating post content\n",
    "\n",
    "\n",
    "    post_data= {\"url\":url, \"title\":post_title, \"category\":post_category, \n",
    "                \"subcategory\":post_subcate, \"username\":post_username, \n",
    "                \"time\":post_time,\"content\":post_content}\n",
    "    \n",
    "    return post_data\n",
    "    \n",
    "    \n",
    "def main_crawler(tails):\n",
    "    batch_post_data= []  #for every 30 posts\n",
    "    for title,url in tails.items():\n",
    "        post_url=get_url(url)\n",
    "        post_data=post_crawler(title,post_url) \n",
    "        batch_post_data.append(post_data)\n",
    "    return batch_post_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "817e3f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page:  321\n",
      "page:  322\n"
     ]
    }
   ],
   "source": [
    "path_to_file=\"filepath.json\"  #replace with true path\n",
    "json_f= open(path_to_file, 'w') \n",
    "\n",
    "json_link_counter=0  \n",
    "is_end=False\n",
    "POST_COUNT_PER_PAGE=30\n",
    "\n",
    "dataset={}  #{post_num:{}}\n",
    "\n",
    "while not is_end:\n",
    "    print(\"page: \",json_link_counter)\n",
    "    is_end,url_tails=url_crawler(json_link_counter) \n",
    "    batch_data= main_crawler(url_tails)\n",
    "    for i in range(len(batch_data)):\n",
    "        post_num = (json_link_counter)*POST_COUNT_PER_PAGE + i +1 \n",
    "        dataset[post_num] = batch_data[i]\n",
    "\n",
    "    json_link_counter+=1\n",
    "\n",
    "json.dump(dataset, json_f)  \n",
    "json_f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
